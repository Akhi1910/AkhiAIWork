{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1 - Processing the data into a usable format for our purposes and cleaning it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install os\n",
    "%pip install datetime\n",
    "%pip install torch\n",
    "%pip install Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock ticker: AAPL\n",
      "Volume of Data (number of days): 8364\n",
      "Opening 5: tensor([[0.4239, 0.4290, 0.4187, 0.4239],\n",
      "        [0.4239, 0.4252, 0.4137, 0.4213],\n",
      "        [0.4252, 0.4367, 0.4252, 0.4290],\n",
      "        [0.4290, 0.4316, 0.4162, 0.4162],\n",
      "        [0.4393, 0.4405, 0.4393, 0.4393]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def load_stock_data():\n",
    "    # Prompt the user to input a stock ticker\n",
    "    ticker = input('Enter a stock ticker: ').upper()\n",
    "\n",
    "    # Construct the filename for the text file\n",
    "    filename = f'C:/archive/Stocks/{ticker.lower()}.us.txt'\n",
    "\n",
    "     # Load the CSV file into a Pandas DataFrame, skipping the first row\n",
    "    df = pd.read_csv(filename, skiprows=1, header=None, names=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Interest'])\n",
    "\n",
    "    # Drop the Date and Interest columns\n",
    "    df = df.drop(['Date', 'Interest', 'Volume'], axis=1)\n",
    "\n",
    "    # Convert the DataFrame to a PyTorch tensor\n",
    "    tensor = torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "    # Output the first 5 rows of the tensor\n",
    "    print(f'Stock ticker: {ticker}')\n",
    "    print(f'Volume of Data (number of days): {tensor.shape[0]}')\n",
    "\n",
    "    print(f'Opening 5: {tensor[:5]}')\n",
    "\n",
    "# Function call for USER\n",
    "load_stock_data()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2 - GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Prompt the user to input a stock ticker\n",
    "ticker = input('Enter a stock ticker: ').upper()\n",
    "\n",
    "    # Construct the filename for the text file\n",
    "filename = f'C:/archive/Stocks/{ticker.lower()}.us.txt'\n",
    "\n",
    "     # Load the CSV file into a Pandas DataFrame, skipping the first row\n",
    "df = pd.read_csv(filename, skiprows=1, header=None, names=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Interest'])\n",
    "\n",
    "    # Drop the Date and Interest columns\n",
    "df = df.drop(['Date', 'Interest', 'Volume'], axis=1)\n",
    "\n",
    "    # Convert the DataFrame to a PyTorch tensor\n",
    "tensor = torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Define the generator model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.hidden_layer = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        x = torch.relu(self.hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Define the discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.hidden_layer = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        x = torch.relu(self.hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Define the GAN model\n",
    "class GAN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.gen_hidden_dim = gen_hidden_dim\n",
    "        self.disc_hidden_dim = disc_hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # Generator model\n",
    "        self.generator = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        # Discriminator model\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(output_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Generator forward pass\n",
    "        z = torch.randn(x.shape[0], input_dim)\n",
    "        fake_data = self.generator(z)\n",
    "\n",
    "        # Discriminator forward pass\n",
    "        disc_output = self.discriminator(fake_data)\n",
    "\n",
    "        return fake_data, disc_output\n",
    "    \n",
    "\n",
    "# Define the training function for the GAN\n",
    "def train_gan(data, epochs, batch_size, input_dim, gen_hidden_dim, disc_hidden_dim, output_dim):\n",
    "    # Initialize the GAN model and the loss functions and optimizers\n",
    "    gan_model = GAN(input_dim, gen_hidden_dim, disc_hidden_dim, output_dim)\n",
    "    disc_loss_fn = nn.BCELoss()\n",
    "    gen_loss_fn = nn.BCELoss()\n",
    "    disc_optimizer = optim.Adam(gan_model.discriminator.parameters(), lr=0.0002)\n",
    "    gen_optimizer = optim.Adam(gan_model.generator.parameters(), lr=0.0002)\n",
    "\n",
    "    # Train the GAN for the specified number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle the data and create batches\n",
    "        np.random.shuffle(data)\n",
    "        data_batches = torch.split(data, batch_size)\n",
    "\n",
    "        for i, batch in enumerate(data_batches):\n",
    "            # Generate fake data with the generator\n",
    "            noise = torch.randn(batch_size, input_dim)\n",
    "            fake_data = gan_model.generator(noise)\n",
    "            num_fake_data = 2000\n",
    "            num_epochs = 100\n",
    "\n",
    "            # Train the discriminator on both real and fake data\n",
    "            disc_optimizer.zero_grad()\n",
    "            real_labels = torch.ones(batch_size, 1)\n",
    "            fake_labels = torch.zeros(batch_size, 1)\n",
    "\n",
    "            real_loss = disc_loss_fn(gan_model.discriminator(batch), real_labels)\n",
    "            fake_loss = disc_loss_fn(gan_model.discriminator(fake_data.detach()), fake_labels)\n",
    "            disc_loss = real_loss + fake_loss\n",
    "            disc_loss.backward()\n",
    "            disc_optimizer.step()\n",
    "\n",
    "            # Train the generator to fool the discriminator\n",
    "            gen_optimizer.zero_grad()\n",
    "            gen_labels = torch.ones(batch_size, 1)\n",
    "            gen_loss = gen_loss_fn(gan_model.d(gan_model.g(noise)), gen_labels)\n",
    "            gen_loss.backward()\n",
    "            gen_optimizer.step()\n",
    "\n",
    "            # Generate some fake data\n",
    "            gan_model.eval()\n",
    "            with torch.no_grad():\n",
    "             fake_data = gan_model.g(torch.randn(num_fake_data, latent_dim, device=device))\n",
    "            fake_data = fake_data.cpu().detach().numpy()\n",
    "\n",
    "        # Append the fake data to the real data tensor\n",
    "        tensor = torch.cat((tensor, torch.tensor(fake_data, dtype=torch.float32)), dim=0)\n",
    "\n",
    "    # Save the generator model\n",
    "    torch.save(gan_model.g.state_dict(), 'generator.pth')\n",
    "\n",
    "    # Return the generated data\n",
    "    return tensor[-num_fake_data:]\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "input_dim = 4\n",
    "latent_dim = 4\n",
    "gen_hidden_dim = 128\n",
    "disc_hidden_dim = 128\n",
    "output_dim = 4\n",
    "gan_model = GAN(input_dim, disc_hidden_dim, output_dim)\n",
    "num_fake_data = 2000\n",
    "\n",
    "\n",
    "fake_data = gan_model.forward(torch.randn(num_fake_data, latent_dim))[0]\n",
    "fake_data = fake_data.cpu().detach().numpy()\n",
    "df = pd.DataFrame(fake_data)\n",
    "\n",
    "tensor = torch.cat((tensor, torch.tensor(fake_data, dtype=torch.float32)), dim=0)\n",
    "# Define the loss functions and optimizers\n",
    "gen_loss_fn = nn.BCELoss()\n",
    "disc_loss_fn = nn.BCELoss()\n",
    "gen_optimizer = optim.Adam(gan_model.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "disc_optimizer = optim.Adam(gan_model.discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "num_samples = 192\n",
    "# Generate fake data using the trained GAN\n",
    "generated_data = gan_model.generator(torch.randn((num_samples, latent_dim)))\n",
    "\n",
    "# Plot the real and generated data over time\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "# Plot the real data\n",
    "ax.plot(tensor[:, 0], label='Real Data1', color='blue')\n",
    "ax.plot(tensor[:, 1], label='Real Data2', color='green')\n",
    "ax.plot(tensor[:, 2], label='Real Data3', color='red')\n",
    "ax.plot(tensor[:, 3], label='Real Data4', color='black')\n",
    "\n",
    "# Plot the generated data\n",
    "ax.plot(generated_data.detach().numpy()[:, 0], label='Generated Data1', color='orange')\n",
    "ax.plot(generated_data.detach().numpy()[:, 1], label='Generated Data2', color='purple')\n",
    "ax.plot(generated_data.detach().numpy()[:, 2], label='Generated Data3', color='brown')\n",
    "ax.plot(generated_data.detach().numpy()[:, 3], label='Generated Data3', color='yellow')\n",
    "\n",
    "# Set the axis labels and title\n",
    "ax.set_xlabel('Time (Days)')\n",
    "ax.set_ylabel('Data Value')\n",
    "ax.set_title('Real and Generated Data')\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Prompt the user to input a stock ticker\n",
    "ticker = input('Enter a stock ticker: ').upper()\n",
    "\n",
    "# Construct the filename for the text file\n",
    "filename = f'C:/archive/Stocks/{ticker.lower()}.us.txt'\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame, skipping the first row\n",
    "df = pd.read_csv(filename, skiprows=1, header=None, names=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Interest'])\n",
    "\n",
    "# Drop the Date and Interest columns\n",
    "df = df.drop(['Date', 'Interest', 'Volume'], axis=1)\n",
    "\n",
    "# Convert the DataFrame to a PyTorch tensor\n",
    "tensor = torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Define the generator model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.hidden_layer = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        x = torch.relu(self.hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.hidden_layer = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        x = torch.relu(self.hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the GAN model\n",
    "class GAN(nn.Module):\n",
    "    def __init__(self, input_dim, gen_hidden_dim, disc_hidden_dim, output_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.gen_hidden_dim = gen_hidden_dim\n",
    "        self.disc_hidden_dim = disc_hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # Generator model\n",
    "        self.generator = nn.Sequential(\n",
    "            nn.Linear(input_dim, gen_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gen_hidden_dim, gen_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gen_hidden_dim, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        # Discriminator model\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(output_dim, disc_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(disc_hidden_dim, disc_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(disc_hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Generator forward pass\n",
    "        z = torch.randn(x.shape[0], self.input_dim)\n",
    "        fake_data = self.generator(z)\n",
    "        # Discriminator forward pass on real data\n",
    "        real_output = self.discriminator(x)\n",
    "\n",
    "    # Discriminator forward pass on fake data\n",
    "        fake_output = self.discriminator(fake_data)\n",
    "\n",
    "        return real_output, fake_output\n",
    "    \n",
    "\n",
    "def train(self, dataloader, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(dataloader):\n",
    "            # Train discriminator\n",
    "            self.discriminator_optimizer.zero_grad()\n",
    "            real_data = data[0].to(self.device)\n",
    "            real_labels = torch.ones(real_data.size(0)).to(self.device)\n",
    "            fake_labels = torch.zeros(real_data.size(0)).to(self.device)\n",
    "\n",
    "            real_output, fake_output = self.forward(real_data)\n",
    "\n",
    "            real_loss = self.loss_function(real_output, real_labels)\n",
    "            fake_loss = self.loss_function(fake_output, fake_labels)\n",
    "            loss = real_loss + fake_loss\n",
    "\n",
    "            loss.backward()\n",
    "            self.discriminator_optimizer.step()\n",
    "\n",
    "            # Train generator\n",
    "            self.generator_optimizer.zero_grad()\n",
    "            z = torch.randn(real_data.size(0), self.input_dim).to(self.device)\n",
    "            fake_data = self.generator(z)\n",
    "\n",
    "            fake_output = self.discriminator(fake_data)\n",
    "\n",
    "            generator_loss = self.loss_function(fake_output, real_labels)\n",
    "\n",
    "            generator_loss.backward()\n",
    "            self.generator_optimizer.step()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print('[Epoch {}/{}], [Step {}/{}], Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'\n",
    "                      .format(epoch, num_epochs, i, len(dataloader), loss.item(), generator_loss.item()))\n",
    "                \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fd1cfc5a787f1ff6635659d3012a72d7cc12b3dd68a70b94b92aa3c71b7fa69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
